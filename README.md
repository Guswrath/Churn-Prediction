Churn Prediction

ğŸ“Œ Project Description

This project aims to predict customer churn (contract cancellation) using the public Telco Customer Churn dataset from Kaggle.

Two machine learning models were implemented and compared:

Logistic Regression (Logit / GLM)
Decision Tree

The main goal is to evaluate their performance using standard classification metrics and provide recommendations for real-world business scenarios.

âš¡ Business Objective

Telecom companies face high customer churn rates.
A predictive model can help:

Identify customers at risk of leaving.
Support retention strategies.
Reduce costs related to customer acquisition.

ğŸ—‚ï¸ Project Structure

Data Cleaning & Preprocessing
Converted categorical and numerical features.
Handled missing values in TotalCharges.
Applied one-hot encoding for categorical variables.
Modeling
Logistic Regression (GLM / logit)
Decision Tree (with max_depth=4 to prevent overfitting)
Evaluation
Accuracy
Precision
Recall
AUC (Area Under the ROC Curve)
Confusion Matrix
ROC Curve Visualization

Results Comparison

Both models achieved good separation ability (AUC 0.84 â€“ 0.86).
Recall was moderate at the default threshold (0.5).
Adjusting the threshold (e.g., 0.3) increases recall, which may be more suitable for churn prediction.

!(https://github.com/Guswrath/Churn-Prediction/blob/main/image.png)

ğŸ“ˆ Key Results

Model	Accuracy	Precision	Recall	AUC
Logistic Regression	0.82	0.69	0.60	0.86
Decision Tree	0.81	0.65	0.52	0.84

ğŸš€ Conclusion

Logistic Regression performed better overall, balancing precision and recall, with higher AUC.

Decision Tree is more interpretable but had lower recall at the default threshold.

For churn prediction, adjusting the decision threshold (e.g., 0.3) is recommended to prioritize recall and capture more at-risk customers.

ğŸ› ï¸ Tech Stack

Python 
Pandas / NumPy
Matplotlib / Seaborn
scikit-learn

ğŸ“‚ Dataset

Telco Customer Churn â€“ Kaggle

ğŸ“Œ Next Steps

Test other algorithms (Random Forest, XGBoost).
Handle class imbalance (SMOTE, undersampling).
Hyperparameter tuning with GridSearchCV.
Optimize threshold based on F1-score or Recall priority.

ğŸ”— Author: Gustavo Martins  â€“ Data Science Portfolio Project

ğŸ‡§ğŸ‡· PortuguÃªs
ğŸ“Œ DescriÃ§Ã£o

Este projeto tem como objetivo prever o churn de clientes (cancelamento de contrato) utilizando o dataset pÃºblico Telco Customer Churn (Kaggle).

Foram implementados dois modelos de machine learning:

RegressÃ£o LogÃ­stica (Logit / GLM)
Decision Tree (Ãrvore de DecisÃ£o)

O objetivo principal Ã© avaliar a performance de cada modelo utilizando mÃ©tricas clÃ¡ssicas de classificaÃ§Ã£o e recomendar a melhor abordagem para o problema de negÃ³cio.

âš¡ Objetivo de NegÃ³cio

Empresas de telecomunicaÃ§Ã£o sofrem com alta taxa de cancelamento de clientes (churn).
Um bom modelo preditivo permite:

Identificar clientes em risco de cancelamento.
Apoiar estratÃ©gias de retenÃ§Ã£o.
Reduzir custos com aquisiÃ§Ã£o de novos clientes.

ğŸ—‚ï¸ Estrutura do Projeto

ImportaÃ§Ã£o e limpeza dos dados
ConversÃ£o de variÃ¡veis numÃ©ricas e categÃ³ricas.
Tratamento de valores nulos na coluna TotalCharges.
One-hot encoding para variÃ¡veis categÃ³ricas.
Modelagem
RegressÃ£o LogÃ­stica (GLM / logit)
Decision Tree (com max_depth=4 para evitar overfitting).
AvaliaÃ§Ã£o
AcurÃ¡cia
PrecisÃ£o
Recall
AUC (Ãrea sob a curva ROC)
Matriz de confusÃ£o
Curva ROC

ComparaÃ§Ã£o de Resultados

Ambos os modelos apresentaram boa capacidade de separaÃ§Ã£o (AUC 0.84 â€“ 0.86).
O recall foi moderado no threshold padrÃ£o (0.5).
Ajustando o threshold (ex: 0.3), Ã© possÃ­vel aumentar recall, o que pode ser mais adequado em churn prediction.



ğŸ“ˆ Principais Resultados

Modelo	AcurÃ¡cia	PrecisÃ£o	Recall	AUC
RegressÃ£o LogÃ­stica	0.82	0.69	0.60	0.86
Ãrvore de DecisÃ£o	0.81	0.65	0.52	0.84


ğŸš€ ConclusÃ£o

A RegressÃ£o LogÃ­stica apresentou melhor equilÃ­brio entre precisÃ£o e recall, alÃ©m de maior AUC.

A Ãrvore de DecisÃ£o Ã© mais interpretÃ¡vel, mas teve recall menor no threshold padrÃ£o.

Para previsÃ£o de churn, recomenda-se ajustar o threshold de decisÃ£o (ex: 0.3) para priorizar recall e identificar mais clientes em risco.

ğŸ› ï¸ Tecnologias Utilizadas

Python
Pandas / NumPy
Matplotlib / Seaborn
scikit-learn

ğŸ“‚ Dataset

Telco Customer Churn â€“ Kaggle

ğŸ“Œ PrÃ³ximos Passos

Testar outros algoritmos (Random Forest, XGBoost).
Balanceamento de classes (SMOTE, undersampling).
Ajuste de hiperparÃ¢metros com GridSearchCV.
OtimizaÃ§Ã£o do threshold com base em F1-score ou Recall como prioridade.

ğŸ”— Author: Gustavo Martins  â€“ Data Science Portfolio Project
